- day: 13
  month: Dez
  title: "Happy Birthday, APPUiO!"
  subtitle: "Rund 80 geladene Gäste feierten Ende November das einjährige Jubiläum von APPUiO im Bogen F in Zürich. Nebst spannenden Kundencases blickten wir auf ein bewegtes erste Jahr zurück und enthüllten die neusten Features der Container Plattform. Abgerundet wurde der Nachmittag mit einer heissen Suppe passend zum Schneegestöber vor der Tür, einer süssen Geburtstagstorte und dem einen oder anderen Bier."
  details: |
            <p>„In kurzer Zeit haben wir viele verschiedene Unternehmen aus unterschiedlichen Branchen für APPUiO begeistert. Wir sind sehr zufrieden mit dieser Entwicklung und sehen weiterhin grosses Potenzial“, sagt Thomas Philipona, Gründungsvater von APPUiO, vor den geladenen Gästen am Jubiläumsevent in Zürich. 
            Das Angebot von APPUiO wurde im vergangenen Jahr optimiert. So gibt es attraktive <a href="https://appuio.ch/#offer">Angebote</a> für Entwickler, die kurzfristig standardisierte Entwicklungsumgebungen in der Cloud suchen, aber auch für Kunden, die eine eigene OpenShift-Plattform nutzen und dabei nichts mit dem Setup und dem Betrieb zu tun haben wollen. „Hier stehen wir gerne als OpenShift-Experten mit unserem Know How zur Verfügung.“</p>

            <h4>Neue Features</h4>

            <p>Im vergangenen Jahr wurden diverse neue Features entwickelt. Es wurde beispielsweise ein Self Service Portal lanciert, über das die Projekte auf Knopfdruck angelegt, vergrössert, gelöscht und verwaltet werden können. Die Kosten der Public Platform werden stündlich berechnet und man bezahlt nur, was auch effektiv genutzt wurde. Zudem wurde eine hybride Cloud mit Cluster auf AWS integriert und verschiedene Managed Services wie 3Scale ins Angebot aufgenommen. Der Austausch in der Community wird mit diversen Events unter Gleichgesinnten sowie einem direkten Draht zum APPUiO-Team über den <a href="https://community.appuio.ch/home">Community Chat</a> gefördert.</p>

            <p>Die Container Plattform wird auch in Zukunft stetig weiterentwickelt: Das Bezahlen mit Kreditkarte, TCP (non-HTTP) Services, Database as a Service, Two-Factor Authentication, Hybrid Migrationen des Workloads, Monitoring as a Service, Backup as a Service, ein Start-up-Pricing sowie weitere interessante Features sind geplant und können in der <a href="https://trello.com/b/kpVq53J2/appuio-roadmap">Roadmap</a> aktiv mitgestaltet werden.</p>


            <h4>Spannende Kundencases</h4>

            <p>Praxisnah und an konkreten Beispielen orientiert, präsentierten <a href="https://www.hrm-systems.ch/de/">HRM Systems AG</a>, <a href="https://www.adcubum.com/home">Adcubum AG</a> und <a href="https://www.amazee.io/">Amazee.io</a>, wie sie APPUiO in ihrem Unternehmen einsetzen. Alle Präsentationen des Nachmittags können <a href="https://speakerdeck.com/appuio">hier</a> angeschaut werden.</p>

            <p>Einblick in den spannenden Nachmittag gibt es auch hier: <a href="https://flic.kr/s/aHsmbCQ3ia">Fotos</a>, <a href="https://vimeo.com/247133328">Video</a></p>


- day: 13
  month: Okt
  title: "Continuous Delivery Pipelines auf APPUiO"
  subtitle: "\"The only thing we know about the future is that it will be different.\" - Peter Drucker"
  details: |
            <p>Continuous Integration, Continuous Deployment und Continuous Delivery sind sehr populäre Begriffe in Zeiten von DevOps, der agilen Software Entwicklung und der Digitalisierung. Die genaue Bedeutung und Definition werden immer noch im Internet diskutiert. Mit diesem Blogpost möchten wir euch den Begriff Continuous Delivery näher bringen und euch aufzeigen, wie wir zusammen mit verschiedenen Kunden auf APPUiO den ganzen Prozess komplett automatisiert haben. Die Kunden sind nun in der Lage ihren Code, ihre Features und Bugfixes innerhalb von kürzester Zeit automatisch zu testen und in die Produktion zu deployen.</p>
            <p>"Early and continuous delivery" von wertbringender Software - so definierte das Agile Manifesto (eine Verkündung der 12 Prinzipien der iterativen Softwareentwicklung) bereits 2001 die Zufriedenstellung des Kundens. Der Begriff Continuous Delivery steht für einen komplexen Ablauf, welcher voll automatisiert und auf Wunsch per Knopfdruck ausgeführt werden soll. Continuous Delivery soll helfen, neue Features, Konfigurationen oder Bugfixes schnell und sicher in die Produktion zu bringen. Dies erlaubt ein frühes Feedback vom Kunden und dadurch eine schnelle Reaktion auf veränderte Marktanforderungen. Der komplette Releaseprozess soll automatisiert ablaufen und dadurch reproduzierbar und auditierbar werden. Automatisierte Tests sollen dabei helfen, Fehler früh zu erkennen und zu beheben. Continuous Delivery heisst also schneller am Markt zu sein, Inhalte eines Releases zu verkleinern und dadurch das Risiko zu reduzieren. Höhere Qualität, weniger Kosten, ein besseres Produkt und glücklichere Teams sind das Resultat.</p>
            <h4>Continuous Delivery hat folgende Eigenschaften:</h4>
            <ul>
            <li>Vollständige Automatisierung der gesamten Pipeline vom Auschecken des Codes bis zum Deployment in die Produktion, um alle Arten von Changes, Features, Bugs, Configuration Changes etc. zuverlässig, sicher und schnell den Benutzern zur Verfügung zu stellen. Einzig die Freigabe für die Produktion wird manuell gemacht zwecks zusätzlicher Kontrolle.

            <li>Jeder Commit der die CI-/CD-Pipeline erfolgreich durchläuft ist ein potentieller Release.<br></li>

            <li>Im Gegensatz zu Continuous Deployment wird der Schritt vom Deployment in die Produktion manuell per Knopfdruck ausgelöst. So kann aus fachlicher oder technischer Sicht entschieden werden, welcher Release wann in Produktion geht. Im Rahmen von Continuous Deployment werden sämtliche potentielle Releases direkt und vollautomatisch in Produktion überführt. Konzepte wie Canary Releasing, Rolling Update, Blue-Green Deployment müssen in hochverfügbaren Umgebungen umgesetzt werden.<br></li>

            <li>Möglichst identische Umgebungen für Entwicklung, Testing, Integration und Produktion.<br></li>
            </ul>
            Weiterführende Informationen findet ihr im Buch von Jez Humble “Continuous Delivery” oder auf seiner WebPage <a href="http://www.continuousdelivery.com">continuousdelivery.com</a>.
            <br><br>
            <h4>Vorteile von Continuous Delivery</h4>
            
            <p><b>Weniger manuelle Tasks, geringere Kosten:</b> Durch die Automatisierung des Releaseprozesses braucht es nicht mehr Stunden, um Code zu paketieren, in die Stages du deployen und manuell zu testen. Diese Schritte werden auf Knopfdruck ausgeführt und reduzieren den Aufwand massiv.<br>
            <br>
            <b>Kürzere Reaktionszeiten/Time-to-Market (schnelleres Feedback, "Fail-fast"):</b> Continuous Delivery (CD) bietet uns die Möglichkeit, täglich Features bis in die Produktion einzuspielen. Daher müssen wir nicht mehr auf ein Wartungsfenster in ferner Zukunft warten. Wir sind mit Neuigkeiten schnell am Markt, schaffen uns einen Marktvorteil, erkennen Fehler viel früher und erhalten zeitnah Rückmeldung von unseren Kunden.<br>
            <br>
            <b>Risikominimierung durch kleinere Releases und automatisierte Tests:</b> Wie z.B. der DevOps Report von Puppet empirisch nachweist, sind die Risiken durch Continuous Delivery massiv kleiner. Kleine, mehrmals täglich ausgerollte Releases, die Möglichkeit, schnell auf Probleme reagieren zu können sowie die gut dokumentierten Änderungen minimieren das Risiko drastisch. Früh erkannte Fehler sind schneller zu beheben und daher oft weniger schmerzhaft.<br>
            <br>
            <b>Reproduzierbarkeit dank Infrastructure as Code:</b> Durch die Automatisierung ist jede Änderung dokumentiert und kann zu jederzeit rückgängig gemacht werden. Die Infrastruktur, der Code, wird aus einem Repository gebuildet und ist daher versioniert.<br>
            <br>
            <b>Kundenzufriedenheit steigt:</b> Weil bereits kleinste Änderungen dem Kunden zur Verfügung gestellt werden können, kann sein Feedback kontinuierlich in die Entwicklung einfliessen. Daher erhält dieser zum Schluss auch wirklich sein gewünschtes Produkt.<br>
            <br>
            <b>Collaboration:</b> Die Automatisierung des Release-Prozesses ist essentiell und die Probleme bei der Auslieferung von Features haben einen wesentlichen Beitrag zur Entstehung des DevOps-Modells geliefert. Die teamübergreifende Zusammenarbeit kann wesentlich verbessert werden, was Reibungspunkte in Firmen reduziert.<br>
            <br>
            <b>Mehr Qualität, weil Bugs frühzeitig erkannt werden:</b> Durch die automatisierten Tests (Integration, Acceptance etc.) können Fehler früher erkannt und noch bevor diese in der Produktion ankommen behoben werden. Dadurch sinkt das Risiko und die Qualität steigt.<br>
            <br>
            <b>Umgebungen können einfach zusammengeschlossen werden:</b> Wie im folgenden Beispiel gezeigt wird, können auf APPUiO die verschiedenen Stages sehr einfach zusammengeschlossen werden. Neue Features und Bugfixes müssen nicht mehr aufwendig auf die verschiedenen Umgebungen manuell kopiert werden.<br></p>
            <br>
            <h4>Wie wird es gemacht? Beispiele anhand von APPUiO</h4>
            <p>Um eine Continuous Delivery Pipeline aufzusetzen und von diesen Vorteilen zu profitieren bietet APPUiO einige Werkzeuge. Mit der OpenShift Container Platform Version 3.4 wurden integrierte Build und Delivery Pipelines eingeführt. Diese technische Neuerung erlaubt es uns, Build- und Delivery-Pipelines direkt in APPUiO zu integrieren und so die volle Flexibilität und Power einer auf Jenkins basierenden Build-Infrastruktur per Knopfdruck - quasi as-a-Service - zu beziehen. Im Gegensatz zum Source to Image (S2I)-Buildverfahren, bei dem der Applikationssourcecode im Rahmen eines einzigen Steps in ein Docker Image verpackt wird, haben wir mit Pipelines die Möglichkeit, deutlich komplexere Abläufe, wie sie in der Realität oft vorkommen, zu implementieren.</p>
 
            <p>So beinhaltet bei uns eine typische Pipeline die folgenden Schritte:</p><br>
            <ul>
            <li>Source Code kompilieren, Codeanalyse und Unit-Tests</li><br>

            <li>Integrationstests und Paketierung (Docker Image, Java Archive)</li><br>

            <li>Deployment auf eine Dev-Umgebung</li><br>

            <li>Automatisierte Tests gegen dieses Deployment</li><br>

            <li>Deployment auf Test-Umgebung</li><br>

            <li>Systemtest</li><br>

            <li>Deployment auf Produktion</li><br>

            <li>Smoketests</li><br>
            </ul>
            <p>Konkret werden sogenannte Jenkins Pipelines als Teil des Source Codes resp. direkt als Teil der Buildconfig der Pipeline als sogenanntes <a href="https://jenkins.io/doc/book/pipeline/jenkinsfile/">Jenkinsfile</a> konfiguriert.
            Beim Erstellen eines solchen Pipeline Builds startet OpenShift dynamisch einen Jenkins und führt die Pipeline darin aus. Benötigte Buildnodes (bspw. Nodejs, Maven, Ruby,...) können dynamisch als Buildnodes in der Pipeline angegeben werden. Sie werden direkt via Jenkins bei Bedarf über den Imagestream referenziert, als Pod deployed und als Step ausgeführt.
            Die Integration der Pipeline direkt in APPUiO sieht dann wie folgt aus:</p>
            <br>
            <img src="/images/pipeline_ocp_view2.png" alt="continuous process"/><br>
            <br>
            <p>Und die analoge Ansicht im integrierten Jenkins:</p><br>
            <img src="/images/pipeline_jenkins_view1.png" alt="continuous process"/>
            <br>
            <p>Auch hier sind die Vorteile vielfältig:
            <ul>
            <li>Sehr gut integriert, Frontend und Backend, Pipelines können auf OpenShift-Ebene direkt kommunizieren.</li><br>

            <li>Buildnodes als Imagestream im OpenShift-Projekt</li><br>

            <li>Secrets werden direkt übernommen, Berechtigungen um Builds und Deployments auf OpenShift auszuführen sind vorkonfiguriert.</li><br>

            <li>Möglichkeit Pipelines stateless zu implementieren, also keine komplexen Buildjobs auf dem Jenkins Master einrichten</li><br>

            <li>Volle Flexibilität von Jenkins Pipelines, beliebige Workflows implementierbar</li><br></p>
            </ul>
            <p>In einem technischen Blogpost werden wir zu einem späteren Zeitpunkt konkret aufzeigen, wie Pipelines in APPUiO integriert werden. Unter <a href="https://github.com/appuio/simple-openshift-pipeline-example">https://github.com/appuio/simple-openshift-pipeline-example</a> haben wir eine simple Beispiel-Pipeline abgelegt.</p>
            <h4>Herausforderungen von Continous Delivery</h4>
            
            <p><b>Organisation und Kultur:</b> APPUiO bietet ein Tooling für die Automatisierung des Releaseprozesses und ist ein wichtiger Teil in dieser schnelllebigen IT-Welt. Eine solche Veränderung hat aber auch Einfluss auf eine Organisation in einem Unternehmen und auf dessen Kultur. Jahrelang wurden Firmen nach Silos aufgeteilt und jeder Mitarbeiter hatte seine spezifische Aufgabe. Nun ist die teamübergreifende Zusammenarbeit gefragt, T-Shaped Engineers, Infrastructure-as-Code usw. Der Mensch ist ein Gewohnheitstier und hat Mühe mit Veränderungen. Daher muss bei einer solchen Umstellung auch ein spezielles Augenmerk auf die Kultur gelegt werden. Ein kultureller Wandel benötigt Zeit.<br>
            <br>
            <b>ISO-Standards, standardisierte Prozesse und Compliance</b> sind wichtige Themen in einem Unternehmen. Dadurch sind auch der Release- und Change-Prozess betroffen. Wie soll es möglich sein, täglich Releases in der Produktion einzuspielen, wenn deren Freigabe Tage dauert? Prozesse und deren Abläufe müssen, wie der Rollout selber, automatisiert und vereinfacht werden.<br>
            <br>
            <b>Technische Umsetzung (CI/CD ToolChain, Software Architektur):</b> Die sogenannte CI-/CD-Toolchain wird mit APPUiO mitgeliefert. Doch die technische Umsetzung betrifft auch die Applikation, welche auf APPUiO deployed werden soll. Eine Legacy Software, die nur manuell updatet werden kann, eignet sich wohl eher weniger für ein Continuous Delivery. Das 12 Factor App Manifest kann hier helfen die wichtigsten Punkte für die Entwicklung einer cloudfähigen Applikation zu berücksichtigen.<br>
            <br>
            <b>Automatisierte Tests</b> können den manuellen Aufwand massiv reduzieren und die Qualität steigern. Doch Integration und End-to-End Tests zu automatisieren kann aufwendig sein und sie müssen, zum Teil, mit den Änderungen am Code angepasst werden. Die Frage stellt sich auch immer, wie kann ich diese Tests automatisieren und habe ich an alle Test Cases gedacht.</p>
            <h4>Fazit</h4>
            <p>Wie bereits Peter Drucker erläutert hat, ist die einzige Konstante in der Zukunft die Veränderung. Die heutige Zeit verlangt nach Agilität und schnellem Feedback. Auf Marktveränderungen muss in kurzer Zeit reagiert werden können. Für die IT ist es deshalb wichtig, Anpassungen und neue Features in kurzer Zeit in die Produktion bringen zu können - ohne dass die Qualität darunter leidet.<br>
            <br>
            Durch Continuous Delivery werden nicht alle Problemfelder beseitigt, die benötigt werden, um mit der Geschwindigkeit der heutigen Zeit standhalten zu können. Ein wichtiger Teil ist auch die Kultur in einem Unternehmen, die Zusammenarbeit und die Architektur der Software. Wir unterstützen euch gerne bei der Integration von Pipelines auf APPUiO oder bei der Automatisierung und Standardisierung eures Entwicklungsprozesses. Auch im Bereich Kultur, DevOps, der Zusammenarbeit in einem Unternehmen oder der Software Architektur haben wir über die Jahre viel Erfahrung gesammelt und geben diese sehr gerne weiter.</p>
    

- day: 10
  month: Okt
  title: "Serverless Computing / Functions as a Service mit APPUiO und Snafu"
  subtitle: "Was ist Serverless, auch FaaS (Function as a Service) genannt?"
  details: |
            <p>Die Begriffe "Serverless" und "FaaS (Function as a Service)" werden in jüngerer Zeit immer öfter in Artikeln erwähnt. Um was geht es eigentlich bei diesem Thema? Unter "FaaS" versteht man die Möglichkeit, eine Programmfunktion "in der Cloud" zu betreiben. Dabei speichert der Entwickler die gewünschte Funktion (egal in welcher Programmiersprache abgefasst, so lange vom Anbieter unterstützt) im FaaS Service der Wahl und ruft diese z.B. über HTTP oder einen Servicebus auf. Dabei muss der Benutzer der Funktion sich weder um die Ausführungsumgebung, Skalierung noch die Konfigurationsdetails eines Applikationsservers kümmern. Daher kommt auch der Begriff "Serverless", welcher sagen möchte, dass die Funktion "einfach läuft", sozusagen ohne Server. Eine Funktion kann eine einfache "Eingabe-Verarbeitung-Ausgabe" Funktion sein, komplexe Berechnungen durchführen oder Daten aus anderen externen Diensten beziehen, verarbeiten und speichern.
            <br><br>
            Der Einsatz von FaaS macht vor allem dann Sinn, wenn es sich um eine spezialisierte Funktion handelt, welche von diversen Microservices verwendet wird. Auch ökonomisch lässt sich der Einsatz von Funktionen in der Cloud gut begründen: Bezahlt wird für der einzelne Funktionsaufruf (je nach Anbieter). Wird die Funktion nicht genutzt, fallen auch keine Kosten an. Dies ist ein "echtes" Cloud Modell, ganz im Sinne von "Pay per Use".
            <br><br></p>

            <h4>Unser Beitrag mit APPUiO und ZHAW SPLab</h4>

            <p>Zusammen mit dem ZHAW <a href="https://blog.zhaw.ch/icclab/category/labs/splab/">Service Prototyping Lab (SPLab)</a> arbeiten wir im Rahmen eines KTI (<a href="https://www.kti.admin.ch/kti/de/home.html">Kommission für Technologie und Innovation</a>) Projekts unter dem Namen "<a href="https://blog.zhaw.ch/icclab/mosaic/">MOSAIC</a>" an Lösungen rund ums Thema FaaS auf APPUiO. Neben einigen Papers (verlinkt im Blogpost von SPLab "<a href="https://blog.zhaw.ch/icclab/snafu-the-swiss-army-knife-of-serverless-computing/">Snafu – The Swiss Army Knife of Serverless Computing</a>") entstand auch ein neues Open Source Projekt: <a href="https://github.com/serviceprototypinglab/snafu">snafu - Snake Functions. The Swiss Army Knife of Serverless Computing</a>. Das Projekt bietet nebst einer lokale Entwicklungsumgebung auch eine Ausführungsumgebung, um Funktionen auf APPUiO zu betreiben. Dabei lassen sich auch Funktionen z.B. von AWS Lambda, Google Cloud Functions oder OpenWhisk importieren und exportieren. So hilft das Tool sowohl beim Entwickeln von Funktionen für die Cloud als auch bei deren Betrieb.
            <br><br></p>

            <h4>Serverless Tools</h4>

            <p>Natürlich gibt es nicht nur Snafu. Es sind mittlerweile eine ganze Reihe von Kandidaten am Markt:<br></p>

            <ul>
            <li><a href="http://kubeless.io/">Kubeless</a> von Bitnami (ehemals Skippbox)<br></li>
            <li><a href="http://fission.io/">Fission</a> von Platform9 Systems<br></li>
            <li><a href="http://open.iron.io/">IronFunctions</a> von <a href="http://Iron.io">Iron.io</a><br></li>
            <li><a href="https://funktion.fabric8.io/">Funktion</a> von Fabric8 / Red Hat<br></li>
            <li><a href="http://openwhisk.incubator.apache.org/">OpenWhisk</a> von der Apache Foundation (Incubator Projekt)<br></li>
            </ul>

            <p>Erst vor kurzem hat sich Red Hat für Apache OpenWhisk entschieden, wie sie in einem Blogpost darlegen: <a href="https://developers.redhat.com/blog/2017/06/07/red-hat-and-apache-openwhisk/">Red Hat and Apache OpenWhisk</a>. Der Plan ist, OpenWhisk als Bestandteil von OpenShift zu integrieren. Es bleibt definitv spannend auf dem Markt, welchen wir sehr nahe verfolgen. Unser Ziel ist es, Funktionen in der Cloud auf APPUiO anbieten zu können und das mit dem passenden Werkzeug.
            <br><br></p>

            <h4>Snafu - Swiss Army Knife of Serverless Computing</h4>

            <p>Snafu kann einerseits als lokale Entwicklungsumgebung dienen, andrerseits aber auch zum Betrieb von Funktionen auf OpenShift. Eine Besonderheit von Snafu ist die Unterstützung des Im- und Exports von Funktionen anderer Anbieter und Tools, wie z.B. AWS Lambda, Google Cloud Functions oder OpenWhisk. Es kann auch dazu benutzt werden, Funktionen zwischen verschiedenen Umgebungen zu migrieren.
            <br><br>
            Architekturdiagramm von Snafu:
            <br><br>
            <img src="/images/Archsnafu.png" alt="continuous process"/>
            <br><br>
            Und so bekommt man Snafu auf die lokale Entwicklungsumgebung (Anleitung für Linux oder MacOS):
            <br><br>
            1 Code clonen</p>

            <pre><code>git clone https://github.com/serviceprototypinglab/snafu.git
            cd snafu
            </code></pre>

            <p>2 Python Virtualenv erstellen</p>

            <pre><code>python -m venv --prompt snafu pyvenv
            . pyvenv/bin/activate
            </code></pre>

            <p>3 Dependencies installieren</p>

            <pre><code>pip install pyesprima flask
            </code></pre>

            <p>4 Snafu benutzen</p>

            <pre><code>% ./snafu [-h]
            % ./snafu --executor &lt;e&gt; --logger &lt;l&gt; --convention &lt;c&gt;
            </code></pre>

            <p>Am Beispiel der mitgelieferten Hello World Funktion:
            <br></p>

            <pre><code>./snafu --executor=inmemory --logger=csv --connector=cli functions/helloworld.py
            » module: functions/helloworld.py
              function: helloworld.helloworld
            + logger: csv
            + executor: java
            + executor: c
            + executor: javascript
            + executor: inmemory
            + connector: cli
            Function name:helloworld.helloworld
            [1503929132.298][140259308811456][function:helloworld.helloworld]
            [1503929132.298][140259308811456][response:helloworld.helloworld/[]]
            [1503929132.298][140259308811456][result:Hello, .]
            [1503929132.298][140259308811456][time:0.003ms]
            [1503929132.298][140259308811456][overalltime:0.011ms]
            Hello, .
            Function name:^C
            Terminated.
            </code></pre>

            <p>In diesem Beispiel wird die Funktion <code>helloworld.helloworld</code> interaktiv ausgeführt und die Ausgabe nach <code>stdout</code> geschrieben. Die Datei <code>snafu.csv</code> beinhaltet nun eine Information über den Aufruf der Funktion für eine spätere Auswertung, wie z.B. zur Verrechnung.
            <br><br></p>

            <h4>Snafu auf OpenShift / APPUiO</h4>

            <p>Snafu kann in verschiedenen Modi betrieben werden. Einer davon ist die direkte Ausführung von Funktionen, welche im Filesystem gespeichert sind. Das erste Beispiel demonstriert diesen Modus, wobei die auszuführende Funktion in einer <a href="https://docs.openshift.org/latest/dev_guide/configmaps.html">ConfigMap</a> (Kubernetes Objekt zur Speicherung der Applikationskonfiguration) gespeichert und Snafu über einen Volume Mount zur Verfügung gestellt wird. Die Speicherung von Funktionen in einer ConfigMap ist als Proof-of-Concept zu verstehen, für einen produktiven Betrieb sind in diesem Beispiel wichtige Themen wie Source Code in Git, CI/CD Rollback, etc. nicht berücksichtigt.
            <br><br>
            Mit folgenden zwei Schritten wird eine einfache Hello World Funktion auf OpenShift deployed:</p>

            <p>1 Neues OpenShift Projekt erstellen oder bei APPUiO bestellen<br>
            2 OpenShift Template initialisieren:</p>

            <pre><code>PROJECT=&lt;myproject&gt;
            oc -n $PROJECT process -f https://raw.githubusercontent.com/serviceprototypinglab/snafu/master/openshift/snafu-template.yaml | oc -n $PROJECT create -f -
            </code></pre>

            <p>Damit ist Snafu installiert und läuft. Das Beispiel startet die Funktion helloworld.helloworld aus der ConfigMap "functions" und stellt sie auf APPUiO unter <a href="http://snafu-$project.appuioapp.ch/invoke/helloworld.helloworld">http://snafu-$PROJECT.appuioapp.ch/invoke/helloworld.helloworld</a> zur Verfügung. Um nun eigene Funktionen zu installieren, editiert man die ConfigMap "functions" und startet den Pod neu, z.B. durch Löschen oder Auslösen eines neuen Deployments. Snafu selbst ist in der ConfigMap "config" konfiguriert.
            <br><br>
            Ein weiterer Modus ist der sogenannte "Control Mode". In diesem verhält sich Snafu wie z.B. ein Amazon Lambda Backend und kann entsprechend mit den AWS Tools benutzt werden. Das folgende Beispiel zeigt, wie Snafu als AWS Lambda-kompatibler Dienst auf OpenShift deployed werden kann:
            <br><br></p>

            <p>1 Neues OpenShift Projekt erstellen oder bei APPUiO bestellen<br>
            2 OpenShift Template initialisieren:</p>

            <pre><code>PROJECT=&lt;myproject&gt;
            oc -n $PROJECT process -f https://raw.githubusercontent.com/serviceprototypinglab/snafu/master/openshift/snafu-control-template.yaml | oc -n $PROJECT create -f -
            </code></pre>

            <p>3 <a href="https://github.com/aws/aws-cli">AWS CLI</a> verwenden</p>

            <pre><code>aws configure
            # AWS Access Key ID [None]: mykey
            # AWS Secret Access Key [None]: myaccesskey
            # Default region name [None]: invalid
            # Default output format [None]:
            alias aws="aws --endpoint-url http://snafu-control-$PROJECT.appuioapp.ch"
            aws lambda list-functions
            aws lambda invoke --function-name lambda.lambda_handler --payload '{"event": "test"}' ./test.out
            cat test.out
            Hello from Lambda
            </code></pre>

            <h4>Weiterführende Informationen</h4>

            <p>Hat dieser Beitrag Ihr Interesse an Serverless / Functions as a Service geweckt? Gerne beantworten wir Ihre Fragen und helfen bei der Implementation: <a href="http://mailto:hello@appuio.ch">hello@appuio.ch</a> oder <a href="http://mailto:info@vshn.ch">info@vshn.ch</a>.
            <br><br>
            <strong>Weitere Informationen zu Snafu können hier gefunden werden:</strong></p>

            <ul>
            <li><a href="https://blog.zhaw.ch/icclab/files/2014/07/serverless-2017-jun.web_.pdf">https://blog.zhaw.ch/icclab/files/2014/07/serverless-2017-jun.web_.pdf</a>: Serverless Applications: Tools, Languages, Providers and (Research) Challenges</li>
            <li><a href="https://arxiv.org/abs/1701.05945">https://arxiv.org/abs/1701.05945</a>: Exploiting the Cloud Control Plane for Fun and Profit</li>
            <li><a href="https://blog.zhaw.ch/icclab/snafu-the-swiss-army-knife-of-serverless-computing/">https://blog.zhaw.ch/icclab/snafu-the-swiss-army-knife-of-serverless-computing/</a>: Snafu – The Swiss Army Knife of Serverless Computing</li>
            <li><a href="https://blog.zhaw.ch/icclab/research-directions-for-faas/">https://blog.zhaw.ch/icclab/research-directions-for-faas/</a>: Research Directions for FaaS</li>
            <li><a href="https://blog.zhaw.ch/icclab/running-google-cloud-functions-in-openshift/">https://blog.zhaw.ch/icclab/running-google-cloud-functions-in-openshift/</a>: Running Google Cloud Functions in OpenShift</li>
            </ul>
            <p><br><br>

- day: 4
  month: Okt
  title: "APPUiO is proud to be mentioned in the ebook \"The State of the Kubernetes Ecosystem\" "
  subtitle: "Kubernetes emerged from a need to run cloud-native applications on a massively scaled network. APPUiO includes Kubernetes as a distribution and is therefore mentioned in the ebook \"The state of the Kubernetes Ecosystem\". "
  details: |
            <img src="/images/appuio_kubernetes_distributor.png" alt="APPUiO as Kubernetes Distributor"/>
            <p>APPUiO allows you to orchestrate and manage containers with Kubernetes. You define how many of your application instances should run in parallel and Kubernetes then takes care of scaling, load balancing and stability.</p>
            <p>The concept of Kubernetes is described in the ebook „The state of the Kubernetes Ecosystem“. It serves as a primer for both newcomers, assessors and implementers who are looking to make the most of the ecosystem of products and services emerging around Kubernetes. </p>
            <p>We are proud to be mentioned with APPUiO among big international brands in this ebook. It motivates to go on working with Kubernetes and bring each day more services to the cloud. </p>
            <p>You can get the ebook <a target="_new" href="https://thenewstack.io/ebooks/kubernetes/state-of-kubernetes-ecosystem/">here</a>.</p>
    
- day: 17
  month: Aug
  title: "Introduction to OpenShift on Exoscale"
  subtitle: "OpenShift is to Kubernetes similar to what a Linux distribution is to the kernel. In this blogpost we show how to integrate OpenShift on <a target=\"_new\" href=\"https://www.exoscale.ch\">Exoscale</a>"
  details: |
            <p>The world is talking about the <a target="_new" rel="noopener" href="https://kubernetes.io/">Kubernetes Project</a></a> - but did you hear about OpenShift? It’s an open source product based on the open source projects Kubernetes and Docker plus a container builder/registry, and a Web GUI to manage it all. This blog post will introduce you to OpenShift and give some hints why to use it, how to get started, and where you can get professional support and managed services.</p>
            <h4>What is OpenShift and why should you use it?</h4>
            <p>It describes itself as “the industry’s most secure and comprehensive enterprise-grade container platform based on industry standards, Docker and Kubernetes”. It’s much more than that - it gives you a complete Kubernetes cluster with many cool features: integrated build pipelines, Docker Registry, Application router (for getting traffic into the cluster), security based on RBAC and SELinux, Web Console for easy access, central logging of all Pod output, Metrics to measure Pod performance, Installation and upgrade using Ansible Playbooks, Source-to-Image builds, and much much more.</p>
            <p>As a Linux distribution acts to the Linux Kernel, OpenShift is a Kubernetes distribution with all the needed tools and tricks to make full use of it.</p>
            <p>OpenShift comes in two flavors:</p>
            <p><ul>
            <li><a target="_new" rel="noopener" href="https://www.openshift.com/container-platform/">OpenShift Container Platform</a>: Software product to install in your data center and get support by Red Hat.</li>
            <li><a target="_new" rel="noopener" href="https://www.openshift.org/">OpenShift Origin</a>: The open source upstream project with a very active GitHub <a target="_new" rel="noopener" href="https://github.com/openshift/origin">repository</a>.</li>
            </ul>
            <img src="/images/feature_process.svg" alt="continuous process"/>
            </p>
            <p>OpenShift enables you to develop faster - after committing your changes in GIT it solves container image build, storage, deploy, scaling, monitoring, and logging for you so you don’t have to do it. The integrated build and deployment processes help you get the developed application to the customer as fast as possible. It enables you to deploy hourly or even faster, and scale computing resources per project automatically with your user base.</p>
            <h4>How to get started?</h4>
            <p>There are many many ways to get started, here are a few hints and examples:</p>
            <p><ul>
            <li>Install your own OpenShift cluster for example on Exoscale with the official <a target="_new" rel="noopener" href="https://github.com/openshift/openshift-ansible">Ansible Playbooks</a>. By using these playbooks you learn to customize every inch of the installation and configuration, and they also help you upgrade from one version to another. Documentation about these playbooks can be found inside the Git repository or on the <a target="_new" rel="noopener" href="https://docs.openshift.org/latest/install_config/install/advanced_install.html">documentation page</a>.</li>
            <li>Start a local OpenShift cluster on your workstation with <a target="_new" rel="noopener" href="https://github.com/minishift/minishift">Minishift</a> (based on Minikube) or with the fancy command oc cluster up. Just download the client binary from the GitHub <a target="_new" rel="noopener" href="https://github.com/openshift/origin/releases">releases page</a>, unpack it, and then run the oc cluster up command. This will launch a complete OpenShift instance on your local Docker Engine:</li>

            <pre><code>% oc cluster up
            Starting OpenShift using openshift/origin:v3.6.0 ...
            Pulling image openshift/origin:v3.6.0
            Pulled 1/4 layers, 28% complete
            Pulled 2/4 layers, 83% complete
            Pulled 3/4 layers, 88% complete
            Pulled 4/4 layers, 100% complete
            Extracting
            Image pull complete
            OpenShift server started.

            The server is accessible via web console at:
                https://127.0.0.1:8443

            You are logged in as:
                User: developer
                Password: &lt;any value&gt;

            To login as administrator:
                oc login -u system:admin
            % oc new-app https://github.com/appuio/example-php-sti-helloworld.git
            [...]
            % oc expose svc example-php-sti-helloworld
            [...]
            % curl -s http://example-php-sti-helloworld-myproject.127.0.0.1.nip.io/ | grep title
                <title>APPUiO PHP Demo</title>
            </code></pre>

            <li>Have a look at the APPUiO <a target="_new" href="https://github.com/appuio/techlab">Techlabs</a> on GitHub which is a free step-by-step introduction to get started. We offer free <a target="_new" href="https://appuio.ch/techlabs.html">half-day workshops</a>.</li>
            <li>The APPUiO <a target="_new" href="http://docs.appuio.ch/en/latest/services/01_introduction.html">Microservices Example</a> documentation gives some insight for developers on how a Microservice application can be built and deployed on OpenShift, describing tools like Gitlab CI and Jenkins for the build pipelines.</li></ul></p>
            <p>There is a lot of documentation available from upstream. It’s a great source to read about every little detail. You’ll find documentation for both the <a target="_new" href="https://docs.openshift.com/">OpenShift Container Platform</a> and <a target="_new" href="https://docs.openshift.org/">OpenShift Origin</a>. APPUiO also provides a <a target="_new" href="http://docs.appuio.ch/en/latest/services/01_introduction.html">community-driven documentation</a>.</p> 
            <p>This blog post was originally published on the <a target="_new" href="https://www.exoscale.ch/syslog/2017/08/15/intro-openshift-exoscale/">Exoscale blog</a>.</p>
- day: 14
  month: Jul
  title: "Ein Jahr Techlabs – ein Rückblick"
  subtitle: "In 15 Techlabs konnten wir über 120 Interessierte von OpenShift begeistern."
  details: "
            <p><strong>Seit <a target=\"new\" href=\"https://www.puzzle.ch/blog/articles/2016/07/18/rueckblick-auf-das-openshift-tech-lab-in-zuerich\">meinem ersten Rückblick auf ein APPUiO & OpenShift Techlab</a> sind unterdessen ein Jahr und 14 weitere Techlabs vergangen. Und wie das so ist, verändert sich in einer so langen Zeit immer ziemlich viel: OpenShift liegt mittlerweile in Version 3.5 vor und weist im Vergleich zu der damaligen Version 3.1 ein weitaus mächtigeres und intuitiveres Webinterface auf. Einiges ist in dieser Zeit aber auch gleich geblieben, unter anderem das Interesse an unseren Techlabs.</strong></p>
            <p>Durch das Update von OpenShift auf die Version 3.4 hat sich bei APPUiO viel verändert. Dank des intuitiveren Webinterface ist nun vieles via Mausklick machbar. Dies setzt insbesondere die Einstiegshürde für Entwickler etwas tiefer. Dass diese Einstiegshürde aber dennoch relativ hoch ist, zeigt die Anzahl Teilnehmende und das Interesse an unseren APPUiO & OpenShift-Techlabs in Bern und Zürich. Die Entwickler besuchen unsere Techlabs nach wie vor rege und lernen dort hands-on die wichtigsten Schritte, wie eine Applikation in die Cloud gebracht wird.</p>
            <p>Andere Dinge sind seit einem Jahr gleich geblieben: so beispielsweise die Container-Grundkonzepte. Oder auch meine Freude, zu sehen, wie die Teilnehmenden immer wieder von Neuem über die technischen Möglichkeiten von OpdenShift begeistert sind. Auch gewisse Fragen tauchen im Rahmen der Techlabs immer wieder auf. Eine der häufigsten ist es, wie denn nun die eigens geschriebene Applikation auf OpenShift deployed werden kann. Hierfür gibt es grundsätzlich drei Möglichkeiten:</p>
            <p><ul>
              <li>OpenShift erstellt mithilfe des integrierten Source-to-Image-Frameworks den Applikations-Pod aus dem reinen Sourcecode. Dabei wird automatisch erkannt, um welche Sprache es sich handelt.</li>
              <li>OpenShift baut den Applikations-Pod mithilfe eines zur Verfügung gestellten Dockerfiles. Dabei wird das Docker Image zuerst gebuildet, in die interne Registry gepusht und anschliessend deployt.</li>
              <li>OpenShift schnappt sich ein bereits gebuildetes Docker Image und deployt dieses. (siehe auch <a target=\"new\" href=\"https://access.redhat.com/articles/2897391\">reference architecture</a>)</li>
            </ul></p>
            <img alt=\"APPUiO OpenShift S2I Deployment Pipeline\" src=\"/images/Blog-Cover-Openshift-03-980x654.png\"/>
            <p><i>Beispiel eines eigens gestrickten S2I-Deployments mit vorhergehendem Build in Jenkins. Die einfachere Variante ist natürlich, ein bereits bestehendes S2I-Script zu verwenden.</i></p>
            <p>Eine ebenfalls häufig gestellte Frage ist, wie lange unsere Labs im Anschluss an den Nachmittag ausprobiert werden können: lange, sehr lange. Unsere Labs sind auf <a target=\"new\" href=\"https://github.com/appuio/techlab/\">GitHub</a> zu finden und eines unserer zusätzlichen Labs beschreibt <a target=\"new\" href=\"https://github.com/appuio/techlab/blob/lab-3.4/additional-labs/development_environment.md\">das Einrichten einer eigenen OpenShift-Entwicklungsumgebung</a>. Dem Ausprobieren zu Hause oder am eigenen Arbeitsplatz steht also nichts im Weg. Und natürlich freuen wir uns auch über Contributions oder Issues, damit wir das Techlab weiter verbessern können.</p>
            <p>Die nächsten Techlabs finden im August und September statt. Wir freuen uns über viele Teilnehmende und sind gespannt auf neue, lehrreiche Erfahrungen!</p>
            <p><strong>Eckdaten Techlabs:</strong></p>
            <p>APPUiO & OpenShift Techlab Bern:<br/>
Wann: Donnerstag, 24. August 2017 ab 14:00 Uhr (Ende ca. 17:30 Uhr)<br/>
Wo: Belpstrasse 37, 3007 Bern (3. Stock)<br/>
<a target=\"new\" href=\"https://app.hatchbuck.com/OnlineForm/71621425243\">Anmeldung</a><br/><br/>
APPUiO & OpenShift Techlab Zürich:<br/>
Wann: Donnerstag, 28. September 2017 ab 14:00 Uhr (Ende ca. 17:30 Uhr)<br/>
Wo: Neugasse 10, 8005 Zürich<br/>
<a target=\"new\" href=\"https://app.hatchbuck.com/OnlineForm/71621425242\">Anmeldung</a></p>
           "
- day: 27
  month: Feb
  title: "2-Tage-Training: From Zero to Hero with Microservices"
  subtitle: "22. und 23. März 2017 bei VSHN AG, Neugasse 10, Zürich"
  details: "
            <img alt=\"From Zero to Hero with Microservices\" src=\"/images/ContainerWorkshop.jpg\"/>
            <p>In diesem Training wirst du eine voll funktionsfähige E-Commerce-Anwendung mit Microservices, Weave Net und Scope, Docker-Container und als Orchestrator APPUiO's Red Hat OpenShift v3 basiert PaaS bauen.</p>
            <p>Dieses Training ist eine ideale Ergänzung zu den kostenlosen APPUiO TechLabs mit mehr Zeit für fundierte Kenntnisse und Zugang zu den Top-Experten.</p>
            <p><a target=\"_blank\" href=\"https://www.eventbrite.com/e/2-day-training-from-zero-to-hero-with-microservices-tickets-30450460146?aff=es2\">Registration</a></p>
           "
- day: 13
  month: Feb
  title: Mini Techlabs an den Voxxed Days 2017
  subtitle: "Die Voxxed Days Zürich kommen am 23. Februar 2017 zurück ins Sihlcity Cinema. Die gesamte Entwickler-Community trifft sich und erfährt das Neuste von inspirierenden Speaker aus der Branche. "
  details: "
            <p>APPUiO ist vor Ort mit einem Stand vertreten. In <strong>Mini Techlabs</strong> zeigen wir den Teilnehmenden hands-on die wichtigsten Schritte, wie eine Applikation in die Cloud gebracht wird und wie Container auf einer PaaS deployed und betrieben werden können. </p>
            <p>Mehr Infos finden Sie unter <a target=\"_blank\" href=\"https://voxxeddays.com/zurich/\">voxxeddays.com/zurich/</a></p>
           "
- day: 13
  month: Jan
  title: Neues Pricing bei APPUiO
  subtitle: Gute Neuigkeiten zum Jahresauftakt
  details: "
            <p>Neu können Sie die Schweizer Container Plattform APPUiO monatlich abonnieren. Für das Public-Angebot bezahlen Sie je nach Paket zwischen 49 Franken und 340 Franken pro Monat. Beim Abschluss eines Jahresvertrags schenken wir Ihnen zwei Monate. </p>
            <p>Mehr Infos finden Sie <a href=\"https://appuio.ch/public.html\">hier</a></p>
           "
